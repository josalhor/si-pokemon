{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644d1959-9e40-45e6-8d3d-1ff3403415f3",
   "metadata": {},
   "source": [
    "# Pokémon competition\n",
    "\n",
    "In this notebook you have to provide the best pipeline that you have found to predict Pokémon battles.\n",
    "\n",
    "At the end you will have to generate a set of predictions over the unlabeled data `data.hidden` and `data_inverse.hidden`. In these unlabeled dataset you will find all the Pokémon battles that we will be performing in some *fictional* Pokémon competition, so we do not know the outcome of these battles right now!\n",
    "\n",
    "Remember to use all the tools that we have seen in class to evaluate and fine-tune your pipeline.\n",
    "\n",
    "*Gotta Predict 'Em All!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654a998-6d49-4762-840d-9caab969e502",
   "metadata": {},
   "source": [
    "Paste here your pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0bef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9eb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Custom functions\"\"\"\n",
    "# Get the list of opposite lables with the current ones\n",
    "def add_opposite_labels(labels):\n",
    "    rt = list(labels)\n",
    "    for l in labels:\n",
    "        rt.append(opposite_label(l))\n",
    "    return rt\n",
    "\n",
    "# Get the list of opposite lables\n",
    "def get_opposite_labels(labels):\n",
    "    return [\n",
    "        opposite_label(l)\n",
    "        for l in labels\n",
    "    ]\n",
    "\n",
    "# Get current labels and opposite ones, to iterate them separetly\n",
    "def double_opposite_labels(labels):\n",
    "    return labels, get_opposite_labels(labels)\n",
    "\n",
    "# Get Opposite of label\n",
    "def opposite_label(label):\n",
    "    other = '__other'\n",
    "    if label.endswith(other):\n",
    "        return label[:-len(other)]\n",
    "    return f'{label}{other}'\n",
    "\n",
    "# Remove prefix from string\n",
    "def remove_prefix(text, prefix):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix):]\n",
    "    return text\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dabd6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Custom classes\"\"\"\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "predict_columns = [\n",
    "    'HP',\n",
    "    'Attack',\n",
    "    'Defense',\n",
    "    'Sp. Atk',\n",
    "    'Sp. Def',\n",
    "    'Speed',\n",
    "    'Generation',\n",
    "    'Legendary'\n",
    "]\n",
    "name_predict_columns = ['Name'] + predict_columns\n",
    "\n",
    "columns_other = {\n",
    "    opposite_label(col): col for col in name_predict_columns\n",
    "}\n",
    "name_columns_other = get_opposite_labels(name_predict_columns)\n",
    "\n",
    "class DeduceFeaturesFromNameTransformer:\n",
    "    # We are going to the deduce\n",
    "    # information about these attributes:\n",
    "    deduce_from_name = ['Type 1', 'Legendary', 'Generation']\n",
    "    def __init__(self):\n",
    "        self.fitted_data = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.deduce_from_name:\n",
    "            self.fit_column(X, col)\n",
    "        return self\n",
    "    \n",
    "    def fit_column(self, X, column):\n",
    "        name_type = X[add_opposite_labels(['Name', column])].dropna()\n",
    "        column_data = {}\n",
    "        for n, t in double_opposite_labels(['Name', column]):\n",
    "            column_data.update(dict(zip(name_type[n],name_type[t])))\n",
    "\n",
    "        to_add = {}\n",
    "        for k, v in column_data.items():\n",
    "            k = remove_prefix(k, 'Mega ')\n",
    "            if k not in column_data:\n",
    "                to_add[k] = v\n",
    "        column_data.update(to_add)\n",
    "        self.fitted_data[column] = column_data\n",
    "\n",
    "    def transform_column(self, X, column):\n",
    "        for n, t in double_opposite_labels(['Name', column]):\n",
    "            filler = X.apply(lambda row: self.fitted_data[column].get(row[n], None), axis=1)\n",
    "            X[t] = X[t].fillna(filler)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for col in self.deduce_from_name:\n",
    "            self.transform_column(X, col)\n",
    "        return X\n",
    "\n",
    "\n",
    "class FillEmptyNonPredictableTransformer:\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for col in add_opposite_labels(['Name', 'Type 2', 'Type 1']):\n",
    "            X[col] = X[col].fillna(value='')\n",
    "        return X\n",
    "\n",
    "\n",
    "class BasePokemonDataCorrectorTransformer:\n",
    "\n",
    "    def __init__(self, attr):\n",
    "        self.trained_attrs = {}\n",
    "        self.attr_to_process = attr #['Name'].extend(attr)\n",
    "\n",
    "    '''\n",
    "    This function should generate and return all values needed to store to\n",
    "    properly proccess a correction in the transform step.\n",
    "    Recieves the selected attr column data\n",
    "    '''\n",
    "    def generate_correction_data(self, data):\n",
    "        return NotImplementedError\n",
    "\n",
    "    '''\n",
    "    This function should determine and if needed correct a value from the\n",
    "    current attr being looked using the correction data generated before.\n",
    "    Recieves the value being processed and the correction data needed\n",
    "    '''\n",
    "    def process_correction(self, value, data):\n",
    "        return NotImplementedError\n",
    "\n",
    "    '''\n",
    "    Joins both combating pokemons into a unique set in order to proccess all \n",
    "    attributes of a known pokemon at the same time\n",
    "    '''\n",
    "    def combine_pokemons(self, X, y=None):\n",
    "        X = X[add_opposite_labels(self.attr_to_process)]\n",
    "        first_half = X[self.attr_to_process]\n",
    "        second_half = X[get_opposite_labels(self.attr_to_process)]\n",
    "        second_half = second_half.rename(columns=columns_other)\n",
    "        return pandas.concat([first_half, second_half])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        unified_pokemons = self.combine_pokemons(X, y)\n",
    "        for name in unified_pokemons['Name'].unique():\n",
    "            selected_pokemon = unified_pokemons[unified_pokemons['Name'] == name]\n",
    "            self.trained_attrs[name] = {}\n",
    "            for attr in self.attr_to_process[1:]:\n",
    "                selected_attr = selected_pokemon[selected_pokemon[attr].notna()][attr]\n",
    "                if len(selected_attr.index) == 0:\n",
    "                    continue\n",
    "                self.trained_attrs[name][attr] = self.generate_correction_data(selected_attr)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        def correct_attr(row, attr):\n",
    "            name = row['Name']\n",
    "            attr_value = row[attr]\n",
    "            if name not in self.trained_attrs or attr not in self.trained_attrs[name]:\n",
    "                return attr_value\n",
    "            return self.process_correction(attr_value, self.trained_attrs[name][attr])\n",
    "\n",
    "        for attr in self.attr_to_process[1:]:\n",
    "            X[attr] = X.apply(lambda row: correct_attr(row, attr), axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "class CategoricalConsensusTransformer(BasePokemonDataCorrectorTransformer):\n",
    "    # Overrides not implemented function\n",
    "    def generate_correction_data(self, data):\n",
    "        return data.mode()[0]\n",
    "\n",
    "    # Overrides not implemented function\n",
    "    def process_correction(self, value, data):\n",
    "        def is_wrong(value, mode):\n",
    "            return value == None or value != mode\n",
    "\n",
    "        mode = data\n",
    "        if not is_wrong(value, mode):\n",
    "            return value\n",
    "        return mode\n",
    "\n",
    "\n",
    "class NumericConsensusTransformer(BasePokemonDataCorrectorTransformer):\n",
    "    # Overrides not implemented function\n",
    "    def generate_correction_data(self, data):\n",
    "        q1 = data.quantile(0.25)\n",
    "        mean = data.mean()\n",
    "        q3 = data.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        max = 1.5 * iqr + q3\n",
    "        min = q1 - 1.5 * iqr\n",
    "        return (min, mean, max)\n",
    "\n",
    "    # Overrides not implemented function\n",
    "    def process_correction(self, value, data):\n",
    "        def is_wrong(value, min, max):\n",
    "            return np.isnan(value) or value > max or value < min\n",
    "\n",
    "        min, mean, max = data\n",
    "        if not is_wrong(value, min, max):\n",
    "            return value\n",
    "        return mean\n",
    "\n",
    "\n",
    "class BothSidesTransformer:\n",
    "    def __init__(self, imputer):\n",
    "        self.imputer = imputer\n",
    "    \n",
    "    def get_halfs(self, X):\n",
    "        first_half = X[predict_columns]\n",
    "        second_half = X[get_opposite_labels(predict_columns)]\n",
    "        second_half = second_half.rename(columns=columns_other)\n",
    "        return first_half, second_half\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        first_half, second_half = self.get_halfs(X)\n",
    "        self.imputer.fit(pandas.concat([first_half, second_half]))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        first_half, second_half = self.get_halfs(X)\n",
    "        first_half_predict = self.imputer.transform(first_half)\n",
    "        second_half_predict = self.imputer.transform(second_half)\n",
    "        X[predict_columns] = first_half_predict\n",
    "        X[get_opposite_labels(predict_columns)] = second_half_predict\n",
    "        return X\n",
    "\n",
    "\n",
    "class KNNImputerBothSidesTransformer(BothSidesTransformer):\n",
    "    def __init__(self):\n",
    "        super().__init__(KNNImputer(n_neighbors=2, weights='distance'))\n",
    "\n",
    "class SimpleImputterBothSidesTransformer(BothSidesTransformer):\n",
    "    def __init__(self):\n",
    "        super().__init__(SimpleImputer(strategy='mean'))\n",
    "\n",
    "\n",
    "class AddPokemonRatiosTransformer:\n",
    "    def __init__(self):\n",
    "        with open('type-chart.json') as f:\n",
    "            self.type_matrix = json.load(f)\n",
    "\n",
    "    def map_row_attack_multipler(self, row, opposite):\n",
    "        all_type_row = ['Type 1', 'Type 2']\n",
    "        if opposite:\n",
    "            type_row = get_opposite_labels(all_type_row)\n",
    "        else:\n",
    "            type_row = all_type_row\n",
    "        best_attack_multiplier = 0.25\n",
    "        at_least_one_type = False\n",
    "        for attack_type in type_row:\n",
    "            attack_type = row[attack_type].lower()\n",
    "            if not attack_type: continue\n",
    "            multiplier = 1\n",
    "            for defense_type in all_type_row:\n",
    "                enemy_defense = defense_type if opposite else opposite_label(defense_type)\n",
    "                defense_type = row[enemy_defense].lower()\n",
    "                if not defense_type: continue\n",
    "                multiplier *= self.type_matrix[attack_type][defense_type]\n",
    "                at_least_one_type = True\n",
    "            best_attack_multiplier = max(best_attack_multiplier, multiplier)\n",
    "        if not at_least_one_type:\n",
    "            return 1\n",
    "        return best_attack_multiplier\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        clean_ratios = X[add_opposite_labels(['Attack', 'Defense', 'Sp. Atk', 'Sp. Def'])]\n",
    "        clean_ratios = X.replace(0, 1)\n",
    "        tmp_rows = {}\n",
    "        for side in [True, False]:\n",
    "            ot_label = '', '__other'\n",
    "            if not side:\n",
    "                ot_label = ot_label[::-1]\n",
    "            first_label, second_label = ot_label\n",
    "            at_def_ratio = X[f'Attack{first_label}'] / clean_ratios[f'Defense{second_label}']\n",
    "            sp_at_def_ratio = X[f'Sp. Atk{first_label}'] / clean_ratios[f'Sp. Def{second_label}']\n",
    "            best_ratio = pandas.concat([at_def_ratio, sp_at_def_ratio], axis=1).max(axis=1)\n",
    "            X[f'best_attack_ratio{first_label}'] = best_ratio\n",
    "\n",
    "            # Is the pokemon a mega evolution?\n",
    "            tmp_rows[f'is_mega{first_label}'] = X[f'Name{first_label}'].str.contains('Mega ', regex=False).astype(int)\n",
    "            stat_sum = X[[f'HP{first_label}', f'Attack{first_label}' , f'Defense{first_label}' , f'Sp. Atk{first_label}' ,f'Sp. Def{first_label}' ,f'Speed{first_label}']].sum(axis=1)\n",
    "            # The sum of stats is a VERY good idicator of how strong a pokemon is\n",
    "            tmp_rows[f'sum_stats{first_label}'] = stat_sum\n",
    "\n",
    "        # Get the best attack multiplier based on types\n",
    "        X['attack_multiplier'] = X.apply(lambda row: self.map_row_attack_multipler(row, opposite=False),axis=1)\n",
    "        # Repeat for the other side\n",
    "        X[opposite_label('attack_multiplier')] = X.apply(lambda row: self.map_row_attack_multipler(row, opposite=True),axis=1)\n",
    "        # This indicator should be correlated with the number of attacks required to kill a pokemon\n",
    "        X['HP_attack'] = X['HP'] / X[opposite_label('attack_multiplier')]\n",
    "        X[opposite_label('HP_attack')] = X[opposite_label('HP')] / X['attack_multiplier']\n",
    "        # Computing the difference of a few metrics is positive for the classification\n",
    "        # HP diff\n",
    "        X['HP_diff'] = X['HP'] - X[opposite_label('HP')]\n",
    "        # Difference attack multiplier\n",
    "        X['attack_multipler_diff'] = X['attack_multiplier'] - X[opposite_label('attack_multiplier')]\n",
    "        # HP attack mult difference\n",
    "        X['HP_attack_multiplier_diff'] = X['attack_multipler_diff'] * X['HP_diff']\n",
    "        # Mega difference\n",
    "        X['mega_diff'] = tmp_rows['is_mega'] - tmp_rows[opposite_label('is_mega')]\n",
    "        # Mega & Lgenendary difference\n",
    "        X['strong_pokemon'] = X['mega_diff'] + X['Legendary'] - X[opposite_label('Legendary')]\n",
    "        # Difference sum stats\n",
    "        X['sum_stats_diff'] = tmp_rows['sum_stats'] - tmp_rows[opposite_label('sum_stats')]\n",
    "        # HP attack difference\n",
    "        X['HP_attack_diff'] = X['HP_attack'] - X[opposite_label('HP_attack')]\n",
    "        # Velocity difference (VERY IMPORTANT)\n",
    "        X['velocity_diff'] =  (X['Speed'] - X['Speed__other'])\n",
    "        # Velocity diff as binary attribute\n",
    "        X['velocity_diff_binary'] =  (X['Speed'] - X['Speed__other']) < 0\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2ccb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=6, min_samples_leaf=5, random_state=SEED)\n",
    "\n",
    "rfc_model = RandomForestClassifier(criterion=\"entropy\", max_depth=9, min_samples_leaf=5, random_state=SEED)\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(6, 4, 2), max_iter=1000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b3e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('dtc', dtc_model), ('rfc', rfc_model), ('mlp', mlp_model)], voting='soft', weights=[1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a648db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tunning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'rfc__n_estimators': list(range(1, 200)),\n",
    "    'rfc__max_depth': list(range(5, 25)),\n",
    "    'dtc__max_depth': list(range(5, 25)),\n",
    "    'mlp__max_iter': list(range(500, 1200)),\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(eclf, parameters, cv=5, n_jobs=-1, n_iter=5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac63015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Proccessing Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "CATEGORICAL = add_opposite_labels(['Type 1', 'Type 2', 'Legendary'])\n",
    "NUMERIC = add_opposite_labels(['HP', 'Attack', 'Defense', 'Sp. Atk',\n",
    "                               'Sp. Def', 'Speed', 'Generation', 'best_attack_ratio',\n",
    "                               'attack_multiplier', 'HP_attack']) + \\\n",
    "    ['attack_multipler_diff', 'sum_stats_diff', 'HP_diff', 'mega_diff',\n",
    "     'HP_attack_diff', 'HP_attack_multiplier_diff',\n",
    "     'strong_pokemon', 'velocity_diff', 'strong_pokemon']\n",
    "BINARY = ['mega_diff', 'velocity_diff_binary'] + \\\n",
    "    add_opposite_labels(['Legendary'])\n",
    "\n",
    "pre_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"data-correction\", make_pipeline(\n",
    "            DeduceFeaturesFromNameTransformer(),\n",
    "            FillEmptyNonPredictableTransformer(),\n",
    "            # adjust known values as there may be outfliers that add noise to the general expected behaviour\n",
    "            NumericConsensusTransformer(\n",
    "                ['Name', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']),\n",
    "            CategoricalConsensusTransformer(\n",
    "                ['Name', 'Legendary']),\n",
    "            # KNN Imputer is better than the Simple Imputter, but way slower\n",
    "            # deduce missing data from the adjusted values\n",
    "            KNNImputerBothSidesTransformer(),\n",
    "            # ('simple', SimpleImputterBothSidesTransformer()),\n",
    "        )),\n",
    "        (\"data-enchancement\", Pipeline(\n",
    "            [\n",
    "                # create retio values that take into account in-game mechanics\n",
    "                # from the raw data\n",
    "                (\"generate_ratios\", AddPokemonRatiosTransformer())\n",
    "            ]\n",
    "        )),\n",
    "        (\"column-transform\", ColumnTransformer(\n",
    "            [\n",
    "                (\n",
    "                    \"cat\",\n",
    "                    OneHotEncoder(sparse_output=True,\n",
    "                                  handle_unknown='ignore'),\n",
    "                    CATEGORICAL\n",
    "                ),\n",
    "                (\"scaler\", StandardScaler(), NUMERIC),\n",
    "                (\"binary\", KBinsDiscretizer(n_bins=2,\n",
    "                                            encode='onehot-dense', strategy='kmeans'), BINARY)\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e27705-202a-4cd5-83a6-3e5e24bae19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "__wd__ = Path(\"__file__\").resolve().parent\n",
    "datasets_path = __wd__ / \"datasets\"\n",
    "\n",
    "data = pandas.read_csv(datasets_path / \"data.train\", index_col=0)\n",
    "inverse_data = pandas.read_csv(datasets_path / \"data_inverse.train\", index_col=0)\n",
    "\n",
    "def get_Xy(dataset):\n",
    "    return dataset.drop(\"Wins\", axis=1), dataset[\"Wins\"]\n",
    "\n",
    "X, y = get_Xy(data)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", pre_pipeline),\n",
    "    (\"ensamble\", clf)\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: WE HAD TO MODIFY THE DO NOT CHANGE THIS CODE PART BECAUSE\n",
    "# IT WAS NOT IDENTICAL TO THE BASIC NOTEBOOK\n",
    "# WE HAD TO ADD index_col=0 TO THE READ CSV METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ab623-dc53-4b71-8bd4-88db538ca049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Do not change this code\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from pathlib import Path\n",
    "\n",
    "__wd__ = Path(\"__file__\").resolve().parent\n",
    "datasets_path = __wd__ / \"datasets\"\n",
    "\n",
    "tournament = pandas.read_csv(datasets_path / \"data.hidden\", index_col=0)\n",
    "tournament_inverse = pandas.read_csv(datasets_path / \"data_inverse.hidden\", index_col=0)\n",
    "\n",
    "y_predicted = pipeline.predict(tournament)\n",
    "y_inverse_predicted = pipeline.predict(tournament_inverse)\n",
    "\n",
    "y_predicted.tofile(\"predicted.csv\", sep=\",\")\n",
    "y_inverse_predicted.tofile(\"predicted_inverse.csv\", sep=\",\")\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Do not change this code\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a40a9907af80ab7544b853e115e9640ce53f7cc981912ef559c1328ace6864ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
